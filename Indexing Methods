{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necessary libiraries\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "import ast\n",
    "import time\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5693, 4)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read And Clean Jobs_Skills Data \n",
    "DF = pd.read_csv(r'E:\\New Moonlit Stage\\iNetworks Intern\\Practical Task #1\\jobs_skills.csv').drop(['_id'], axis=1)\n",
    "DF = DF[(DF.skills != \"['nan']\") & (DF.title != \"['nan']\") & (DF.jobFunction != \"['nan']\") & (DF.industry != \"['nan']\")].drop_duplicates()\n",
    "DF.skills = DF.skills.replace(r'[^\\w\\s ()]', ' ')\n",
    "#print(DF.skills[150][0])\n",
    "DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleansing The Job Titles Function ##\n",
    "def clean_job_titles_list(job_titles_list):\n",
    "    all_job_titles = [ str(cleaned_title) for cleaned_title in job_titles_list ]\n",
    "    all_job_titles = [ title.split(' - ')[0].strip().lower().split(',')[0].split('@')[0].strip().split(\" at \")[0].strip().split('\\\\u')[0] for title in all_job_titles  if \"-end\" != title.lower()]\n",
    "    all_job_titles = [ title.encode('ascii', 'ignore').decode(\"utf-8\").replace(\"[fcis19]\",'').split(\" for \")[0].split(\" in \")[0].strip() for title in all_job_titles ]\n",
    "    all_job_titles = [ title.split(\"(\")[0].strip() for title in all_job_titles]\n",
    "    cleaned_job_titles = []\n",
    "    for title in all_job_titles:\n",
    "        if len(title.split(\"|\")) >= 2:\n",
    "            cleaned_job_titles.append(title.split(\"|\")[0].strip() + \" | \" + title.split(\"|\")[1].strip())\n",
    "        else: \n",
    "            cleaned_job_titles.append(title.strip())\n",
    "    return cleaned_job_titles\n",
    "DF.title = clean_job_titles_list(DF.title)\n",
    "Skills = [ast.literal_eval(skill) for skill in DF.skills]\n",
    "DF['skills'] = Skills\n",
    "#print(DF.skills[100] , DF.skills[100][0] , type(DF.skills[100]) , type(DF.skills[100][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Cleaned Version Of The Data\n",
    "DF.to_csv('Cleaned_Version1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coll']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################\n",
    "## Define Mongo Configrations \n",
    "###############################\n",
    "Client = MongoClient('localhost',27017)\n",
    "DB = Client.Jobs_Skills\n",
    "Collection = DB.Coll\n",
    "DB.segment.drop()\n",
    "DB.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting CSV To JSON Format\n",
    "DF = pd.read_csv('Cleaned_Version1.csv', index_col=0) \n",
    "JSON_ = json.loads(DF.to_json(orient='records'))\n",
    "for document in JSON_:\n",
    "    document.pop('Unnamed: 0.1', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'property consultant', 'jobFunction': \"['Sales/Retail']\", 'industry': \"['Real Estate/Property Management']\", 'skills': \"['Sales', 'Retail', 'Real Estate', 'Sales Target', 'Indoor Sales', 'Sales Skills', 'Property Sales']\"}\n"
     ]
    }
   ],
   "source": [
    "print(JSON_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5693\n"
     ]
    }
   ],
   "source": [
    "# Insert JSON Documents\n",
    "Collection.delete_many({})\n",
    "Collection.insert_many(JSON_)\n",
    "print(Collection.estimated_document_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coll']\n",
      "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'Jobs_Skills'), 'Coll.inserted_ids')\n"
     ]
    }
   ],
   "source": [
    "print(DB.list_collection_names())\n",
    "print(Collection.inserted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Time after Indexing in second:  0.022029399871826172\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# Searching Before Indexing\n",
    "start_time = time.time()\n",
    "result2 = pd.DataFrame(list(Collection.find({\"title\" :\"admin assistant\"})))\n",
    "end_time = time.time()\n",
    "search_time_after_indexing = end_time - start_time\n",
    "print ( 'Search Time after Indexing in second: ', search_time_after_indexing)\n",
    "#print(len(result2))\n",
    "print(Collection.count_documents({\"title\" :\"admin assistant\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Time before Indexing in second:  0.02403855323791504\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# Searching with Indexing \n",
    "Collection.create_index([(\"title\", pymongo.TEXT)], name=\"search_index\",default_language='english')\n",
    "start_time = time.time()\n",
    "result = pd.DataFrame(list(Collection.find({\"title\": \"admin assistant\"})))\n",
    "end_time = time.time()\n",
    "search_time_before_indexing = end_time - start_time\n",
    "print ('Search Time before Indexing in second: ', search_time_before_indexing)\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sorted(list(DB.collection.index_information())))\n",
    "#print(DB.collection.getIndexes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5693"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Collection.estimated_document_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    }
   ],
   "source": [
    "# Elastic Search Connection\n",
    "ES = None\n",
    "ES = Elasticsearch()\n",
    "if ES.ping():\n",
    "    print('Connected!')\n",
    "else:\n",
    "    print('Server could not connect!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index IS Created\n"
     ]
    }
   ],
   "source": [
    "ES.indices.delete(index='skill')\n",
    "# Create Index\n",
    "created = False\n",
    "# index settings\n",
    "settings = {\n",
    "        \"settings\": {\"number_of_shards\": 1, \"number_of_replicas\": 0},\n",
    "        \"mappings\": {\"dynamic\": \"strict\", \"properties\": {\"title\": {\"type\": \"text\"}, \"jobFunction\": {\"type\": \"text\"}, \"industry\": {\"type\": \"text\"},\"skills\": {\"type\": \"text\"},\n",
    "                    \"ingredients\": {\"type\": \"object\",\"properties\": {\"step\": {\"type\": \"text\"}}}, }}}   \n",
    "try:\n",
    "        if not ES.indices.exists('skill'):\n",
    "            ES.indices.create(index='skill', ignore=400, body=settings)\n",
    "            print('Index IS Created')\n",
    "        created = True\n",
    "except Exception as ex:\n",
    "    print(str(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'skill': {'mappings': {'dynamic': 'strict', 'properties': {'industry': {'type': 'text'}, 'ingredients': {'properties': {'step': {'type': 'text'}}}, 'jobFunction': {'type': 'text'}, 'skills': {'type': 'text'}, 'title': {'type': 'text'}}}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'sales representative',\n",
       " 'jobFunction': \"['Customer Service/Support', 'Sales/Retail']\",\n",
       " 'industry': \"['Real Estate/Property Management']\",\n",
       " 'skills': \"['Sales', 'Real Estate', 'Sales Target', 'Customer Service', 'Customer Care', 'Sales Skills']\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ES.indices.get_mapping('skill'))\n",
    "JSON_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# Store JSON File In The Index\n",
    "try:\n",
    "    for record in JSON_:\n",
    "        outcome = ES.index(index='skill', body=record)\n",
    "    print('DONE!')  \n",
    "except Exception as ex:\n",
    "    print('Error in indexing data')\n",
    "    print(str(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5693\n",
      "{'_index': 'skill', '_type': '_doc', '_id': '46Q0f3ABWxGDBVvQN5EP', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 5692, '_primary_term': 1}\n"
     ]
    }
   ],
   "source": [
    "print(len(JSON_))\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Query\n",
    "Search = {'query': {'match': {'skills': 'Machine Learning'}}}\n",
    "Result = ES.search(index='skill', body=Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'senior machine learning engineer', 'jobFunction': \"['IT/Software Development', 'Engineering - Telecom/Technology']\", 'industry': \"['Computer Software']\", 'skills': \"['CNN', 'TensorFlow', 'Startup', 'Python', 'RNN', 'Computer Science', 'Machine Learing', 'Architecture', 'C++', 'Design', 'Theano', 'NLP', 'Engineering', 'Machine Learning', 'Statistics']\"}\n",
      "{'title': 'machine learning engineer', 'jobFunction': \"['IT/Software Development', 'Engineering - Telecom/Technology']\", 'industry': \"['Music', 'Computer Software', 'Computer and Network Security']\", 'skills': \"['Python', 'Software Development', 'Computer Science', 'NLP', 'Information Technology (IT)', 'Machine Learning', 'SQL', 'Java']\"}\n",
      "{'title': 'senior data scientist', 'jobFunction': \"['IT/Software Development', 'Engineering - Telecom/Technology']\", 'industry': \"['Engineering Services']\", 'skills': \"['PowerBI', 'Agile', 'Python', 'C#', 'SAS', 'Git', 'C++', 'Oracle', 'PySpark', 'Information Technology (IT)', 'Machine Learning', 'SQL', 'Java']\"}\n",
      "{'title': 'machine learning engineer', 'jobFunction': \"['IT/Software Development', 'Engineering - Telecom/Technology']\", 'industry': \"['Engineering Services']\", 'skills': \"['PowerBI', 'Python', 'DevOps', 'OOP', 'Linux', 'Tableau', 'Microsoft SQL Server', 'PySpark', 'MLlib', 'NLP', 'Information Technology (IT)', 'Machine Learning']\"}\n",
      "{'title': 'data scientist', 'jobFunction': \"['IT/Software Development', 'Analyst/Research']\", 'industry': \"['Healthcare and Medical Services']\", 'skills': \"['Mathematics', 'Python', 'Startup', 'Data Analysis', 'Data Science', 'ML Toolkits', 'Healthcare', 'ML Algorithms', 'Apache Spark', 'Information Technology (IT)', 'Machine Learning']\"}\n",
      "{'title': 'senior machine learning engineer', 'jobFunction': \"['IT/Software Development', 'Engineering - Telecom/Technology', 'Analyst/Research']\", 'industry': \"['Information Technology Services', 'Computer Software']\", 'skills': \"['Python', 'Text Mining', 'ElasticSearch', 'Natural Language Processing', 'Information Retrieval', 'Data Science', 'Pandas', 'Data Scientist', 'Flask', 'Web Development', 'NLP', 'MySQL', 'Software Engineering', 'Machine Learning', 'Recommender Systems']\"}\n",
      "{'title': 'senior machine learning engineer', 'jobFunction': \"['Engineering - Telecom/Technology', 'IT/Software Development', 'Analyst/Research']\", 'industry': \"['Information Technology Services', 'Computer Software']\", 'skills': \"['Python', 'ElasticSearch', 'Machine Learning', 'Web Development', 'Pandas', 'Information Retrieval', 'Text Mining', 'Recommender Systems', 'Natural Language Processing', 'Software Engineering', 'Flask', 'NLP', 'MySQL', 'Data Science', 'Data Scientist']\"}\n",
      "{'title': 'big data engineer', 'jobFunction': \"['IT/Software Development', 'Engineering - Telecom/Technology']\", 'industry': \"['Engineering Services', 'Computer Software']\", 'skills': \"['Python', 'NoSQL', 'TensorFlow', 'Apache Cassandra', 'Math', 'MapReduce', 'Machine Learning Model', 'Docker Containers', 'Hive', 'Kafka', 'Linux', 'Spark Streaming', 'Flink', 'Big Data', 'Computer Science', 'Java', 'Hadoop', 'Big Data Development', 'Sqoop', 'Pig', 'Statistics']\"}\n",
      "{'title': 'machine learning engineer', 'jobFunction': \"['IT/Software Development', 'Engineering - Telecom/Technology', 'Analyst/Research']\", 'industry': \"['Information Technology Services']\", 'skills': \"['Python', 'CSS', 'Django', 'javaScript', 'HTML', 'Software Engineering', 'RESTful API', 'Software Testing', 'Data Mining', 'NLTK', 'Flask', 'Object-oriented Design', 'Machine Learning', 'Kubernetes', 'Docker', 'Computer Science', 'Tensor Flow', 'Sklearn', 'GCP', 'React js', 'AWS']\"}\n",
      "{'title': 'python full stack developer', 'jobFunction': \"['IT/Software Development', 'Engineering - Telecom/Technology']\", 'industry': \"['Information Technology Services', 'Computer Software', 'Graphic Design']\", 'skills': \"['Python', 'Django', 'javaScript', 'Git', 'jQuery', 'Software Engineering', 'MySQL', 'Angular', 'Troubleshooting', 'Engineering', 'Unix-Based', 'Debugging', 'SQL', 'Machine Learning', 'Data Analytics', 'Server Management', 'Computer Sciene', 'Data Science', 'Computer Engineering', 'Information Technology (IT)', 'Angular.js', 'Pandas', 'Unit Testing', 'Backend']\"}\n",
      "\n",
      "Process time:  0.0009989738464355469\n"
     ]
    }
   ],
   "source": [
    "# Get The Matched Documents Of The Query\n",
    "before_time = time.time()\n",
    "for Doc in Result['hits']['hits']:\n",
    "    print(Doc['_source'])\n",
    "after_time = time.time()\n",
    "print(\"\\nProcess time: \", after_time - before_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ES.indices.delete(index='jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'jobs'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete index if exists\n",
    "if ES.indices.exists(\"jobs\"):\n",
    "    ES.indices.delete(index=\"jobs\")\n",
    "# index settings\n",
    "settings = {\"settings\": {\"number_of_shards\": 1,\"number_of_replicas\": 0},\n",
    "            \"mappings\": {\"properties\": {'title': {'type': 'text'},'jobFunction' : {'type': 'text'},'industry' : {'type': 'text'},'skills':{'type': 'text'},'url':{'type': 'text'}}}}\n",
    "# create index\n",
    "ES.indices.create(index=\"jobs\", ignore=400, body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n",
      "{'_index': 'jobs', '_type': '_doc', '_id': '29', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 29, '_primary_term': 1}\n"
     ]
    }
   ],
   "source": [
    "# Import Data from MongoDB Into Elastic \n",
    "for index,job in enumerate(Collection.find().limit(30)):\n",
    "    del job['_id']\n",
    "    Out = ES.index(index='jobs', id=index, body=job)\n",
    "print('DONE!')\n",
    "print(Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'administrator & document controller', 'jobFunction': \"['Administration']\", 'industry': \"['Real Estate/Property Management']\", 'skills': \"['Organizing', 'Printing', 'Scanning', 'Copying', 'Document Control', 'Administration']\"}\n",
      "\n",
      "Process time:  0.5488042831420898\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "res = ES.get(index='jobs', id=14)\n",
    "print(res['_source'])\n",
    "end_time = time.time()\n",
    "print(\"\\nProcess time: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
